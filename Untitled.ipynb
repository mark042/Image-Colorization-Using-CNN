{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "           ---- DEEP LEARNING COLORIZATION FOR VISUAL MEDIA ----           \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage import io, color\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import misc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sess = tf.InteractiveSession() \n",
    "\n",
    "#region Intialize Data and Layers weights\n",
    "ColorImgsPath = r'E:\\Cs\\GP\\Code\\DP\\TestColor/'\n",
    "GreyImgsPath = r'E:\\Cs\\GP\\Code\\DP\\TestGrey/'\n",
    "TestingImgPath = r'C:\\Colorization Model/'\n",
    "ResultImagePath = r'C:\\Colorization Model/'\n",
    "\n",
    "AbColores_values = None\n",
    "GreyImages_Batch = [] \n",
    "ColorImages_Batch = []\n",
    "Batch_size = 1\n",
    "CurrentBatch_indx = 1\n",
    "EpochsNum = 100\n",
    "ExamplesNum = 4    # Number of all Images in Db Dir\n",
    "Imgsize = 224, 224 \n",
    "GreyChannels = 1\n",
    "ML_OUTPUT = None \n",
    "Fusion_output = None\n",
    " \n",
    "Low_weights = {'W_conv1':tf.Variable(tf.truncated_normal([3,3,1,64], stddev=0.001),name=\"Low1\"),\n",
    "               'W_conv2':tf.Variable(tf.truncated_normal([3,3,64,128], stddev=0.001),name=\"Low2\"),\n",
    "               'W_conv3':tf.Variable(tf.truncated_normal([3,3,128,128], stddev=0.001),name=\"Low3\"),\n",
    "               'W_conv4':tf.Variable(tf.truncated_normal([3,3,128,256], stddev=0.001),name=\"Low4\"), \n",
    "               'W_conv5':tf.Variable(tf.truncated_normal([3,3,256,256], stddev=0.001),name=\"Low5\"),\n",
    "               'W_conv6':tf.Variable(tf.truncated_normal([3,3,256,512], stddev=0.001),name=\"Low6\")}\n",
    " \n",
    "Low_biases = {'b_conv1':tf.Variable(tf.truncated_normal([64], stddev=0.001)),\n",
    "              'b_conv2':tf.Variable(tf.truncated_normal([128], stddev=0.001)),\n",
    "              'b_conv3':tf.Variable(tf.truncated_normal([128], stddev=0.001)),\n",
    "              'b_conv4':tf.Variable(tf.truncated_normal([256], stddev=0.001)),\n",
    "              'b_conv5':tf.Variable(tf.truncated_normal([256], stddev=0.001)),\n",
    "              'b_conv6':tf.Variable(tf.truncated_normal([512], stddev=0.001))}\n",
    " \n",
    "Mid_weights = {'W_conv1':tf.Variable(tf.truncated_normal([3,3,512,512], stddev=0.001)),\n",
    "               'W_conv2':tf.Variable(tf.truncated_normal([3,3,512,256], stddev=0.001))}\n",
    " \n",
    "Mid_biases = {'b_conv1':tf.Variable(tf.truncated_normal([512], stddev=0.001)),\n",
    "              'b_conv2':tf.Variable(tf.truncated_normal([256], stddev=0.001))}\n",
    " \n",
    "Global_weights = {'W_conv1':tf.Variable(tf.truncated_normal([3,3,512,512], stddev=0.001)),\n",
    "                  'W_conv2':tf.Variable(tf.truncated_normal([3,3,512,512], stddev=0.001)),\n",
    "                  'W_conv3':tf.Variable(tf.truncated_normal([3,3,512,512], stddev=0.001)),\n",
    "                  'W_conv4':tf.Variable(tf.truncated_normal([3,3,512,512], stddev=0.001))}\n",
    " \n",
    "Global_biases = {'b_conv1':tf.Variable(tf.truncated_normal([512], stddev=0.001)),\n",
    "                 'b_conv2':tf.Variable(tf.truncated_normal([512], stddev=0.001)),\n",
    "                 'b_conv3':tf.Variable(tf.truncated_normal([512], stddev=0.001)),\n",
    "                 'b_conv4':tf.Variable(tf.truncated_normal([512], stddev=0.001))}\n",
    " \n",
    "Color_weights = {'W_conv1':tf.Variable(tf.truncated_normal([3,3,512,256], stddev=0.001)),\n",
    "                 'W_conv2':tf.Variable(tf.truncated_normal([3,3,256,128], stddev=0.001)),\n",
    "                 'W_conv3':tf.Variable(tf.truncated_normal([3,3,128,64], stddev=0.001)),\n",
    "                 'W_conv4':tf.Variable(tf.truncated_normal([3,3,64,64], stddev=0.001)),\n",
    "                 'W_conv5':tf.Variable(tf.truncated_normal([3,3,64,32], stddev=0.001)),\n",
    "                 'W_conv6':tf.Variable(tf.truncated_normal([3,3,32,2], stddev=0.001))}\n",
    " \n",
    "Color_biases = {'b_conv1':tf.Variable(tf.truncated_normal([256], stddev=0.001)),\n",
    "                    'b_conv2':tf.Variable(tf.truncated_normal([128], stddev=0.001)),\n",
    "                    'b_conv3':tf.Variable(tf.truncated_normal([64], stddev=0.001)),\n",
    "                    'b_conv4':tf.Variable(tf.truncated_normal([64], stddev=0.001)),\n",
    "                    'b_conv5':tf.Variable(tf.truncated_normal([32], stddev=0.001)),\n",
    "                    'b_conv6':tf.Variable(tf.truncated_normal([2], stddev=0.001))}    \n",
    "  \n",
    "MLnode_for_each_layer = [1024, 512, 256]\n",
    "MLHidden_layer = []\n",
    "MLHidden_layer.append({'weights': tf.Variable(tf.truncated_normal([7 * 7 * 512, MLnode_for_each_layer[0]], stddev=0.001)),\n",
    "                     'biases': tf.Variable(tf.truncated_normal([MLnode_for_each_layer[0]],stddev=0.001))})\n",
    "for i in range(1, 3):\n",
    "    MLHidden_layer.append({'weights': tf.Variable(tf.truncated_normal([MLnode_for_each_layer[i - 1], MLnode_for_each_layer[i]], stddev=0.001)),\n",
    " \n",
    "                         'biases': tf.Variable(tf.truncated_normal([MLnode_for_each_layer[i]], stddev=0.001))})\n",
    " \n",
    " #endregion\n",
    "\n",
    "def Fusion_layer(MiddNetOutput, GlobalNetOutput,BatchSize,H,W):\n",
    "    \"\"\"A network that fuses the output of midd Net  and output of MLP(Global) Net\n",
    "    together.\n",
    "    Args:\n",
    "    MiddNetOutput: Size of [?, H/8, W/8, 256].\n",
    "    GlobalNetOutput: Size of [?,256]\n",
    "    \"\"\" \n",
    "    H= tf.cast((H/8), tf.int32) \n",
    "    W= tf.cast((W/8), tf.int32) \n",
    "   \n",
    "    GlobalNetOutput = tf.tile(GlobalNetOutput,[1,H * W])\n",
    "    GlobalNetOutput = tf.reshape(GlobalNetOutput,[Batch_size,H,W,256])\n",
    "    Fusion_output = tf.concat(3,[MiddNetOutput,GlobalNetOutput])\n",
    "    return Fusion_output  \n",
    "\n",
    "def ConstructML(input_tensor, layers_count, node_for_each_layer):\n",
    "    \"\"\"A fully connected Network MLP connected to Global Feature outputs\n",
    "    Args:\n",
    "    input_tensor : the output of global feature , shape = [ 1, 7, 7, 512]\n",
    "    layer_count : number of layer in MLP actually = 3 or more\n",
    "    node_for_each_layer : a list contains number of nodes in each layer [ 1024, 512, 256]\n",
    "    \"\"\"\n",
    "    global   ML_OUTPUT \n",
    " \n",
    "    FeatureVector = tf.reshape(input_tensor,shape=[-1,7 * 7 * 512])\n",
    "    layers_output = tf.add(tf.matmul(FeatureVector, MLHidden_layer[0]['weights']), MLHidden_layer[0]['biases'])\n",
    "    layers_output = tf.nn.relu(layers_output)\n",
    " \n",
    "    for j in range(1, layers_count):\n",
    "        layers_output = tf.add(tf.matmul(layers_output, MLHidden_layer[j]['weights']), MLHidden_layer[j]['biases'])\n",
    "        layers_output = tf.nn.relu(layers_output)\n",
    " \n",
    "    ML_OUTPUT = layers_output    \n",
    "    return ML_OUTPUT\n",
    "\n",
    "def Conv2d(inp, W ,Stride):\n",
    "   \"\"\"Computes a 2-D convolution over a 4-D input\n",
    "    Args:\n",
    "    inp: 4-D tensor\n",
    "    W: Kernel\n",
    "    Stride: The kenrel stride over the input\n",
    "    \"\"\"\n",
    "   return tf.nn.conv2d(inp, W, strides=[1, Stride ,Stride, 1], padding='SAME')\n",
    "\n",
    "def ReadNextBatch(): \n",
    "    '''Reads the Next (grey,Color) Batch and computes the Color_Images_batch Chrominance (AB colorspace values)\n",
    " \n",
    "    Return:\n",
    "     GreyImages_Batch: List with all Greyscale images [Batch size,224,224,1]\n",
    "     ColorImages_Batch: List with all Colored images [Batch size,Colored images]\n",
    "    '''\n",
    "    global GreyImages_Batch\n",
    "    global ColorImages_Batch\n",
    "    global CurrentBatch_indx\n",
    "    global Batch_size\n",
    "    GreyImages_Batch = []\n",
    "    ColorImages_Batch = []\n",
    "    for ind in range(Batch_size):\n",
    "        Colored_img = Image.open(ColorImgsPath + str(CurrentBatch_indx) + '.png')\n",
    "        ColorImages_Batch.append(Colored_img)\n",
    "        Grey_img = Image.open(GreyImgsPath + str(CurrentBatch_indx) + '.png')        \n",
    "        Grey_img = np.asanyarray(Grey_img) \n",
    "        img_shape = Grey_img.shape\n",
    "        img_reshaped = Grey_img.reshape(img_shape[0],img_shape[1], GreyChannels)#[224,224,1]\n",
    "        GreyImages_Batch.append(img_reshaped)#[#imgs,224,224,1]\n",
    "        CurrentBatch_indx = CurrentBatch_indx + 1\n",
    "    Get_Batch_Chrominance() \n",
    "    return GreyImages_Batch\n",
    "\n",
    "def Get_Batch_Chrominance():\n",
    "    ''''Convert every image in the batch to LAB Colorspace and normalize each value of it between [0,1]\n",
    " \n",
    "    Return:\n",
    "     AbColores_values array [batch_size,2224,224,2] 0-> A value, 1-> B value color\n",
    "    '''\n",
    "    global AbColores_values\n",
    "    global ColorImages_Batch\n",
    "    AbColores_values = np.empty((Batch_size,224,224,2),\"float32\")\n",
    "    for indx in range(Batch_size):\n",
    "        lab = color.rgb2lab(ColorImages_Batch[indx])\n",
    "        Min_valueA = np.amin(lab[:,:,1])\n",
    "        Max_valueA = np.amax(lab[:,:,1])\n",
    "        Min_valueB = np.amin(lab[:,:,2])\n",
    "        Max_valueB = np.amax(lab[:,:,2])\n",
    "        AbColores_values[indx,:,:,0] = Normalize(lab[:,:,1],-128,127)\n",
    "        AbColores_values[indx,:,:,1] = Normalize(lab[:,:,2],-128,127)\n",
    "\n",
    "def Normalize(value,MinValue,MaxValue):\n",
    "    '''Normalize the input value between specific range\n",
    " \n",
    "    Args:\n",
    "     value = pixel value\n",
    "     MinValue = Old Min value\n",
    "     MaxValue = Old Max value\n",
    " \n",
    "   Return:\n",
    "    Normalized Value\n",
    "    '''\n",
    " \n",
    "    MinNormalize_val = 0\n",
    "    MaxNormalize_val = 1\n",
    "    value = MinNormalize_val + (((MaxNormalize_val - MinNormalize_val) * (value - MinValue)) / (MaxValue - MinValue))\n",
    "    return value\n",
    "\n",
    "def DeNormalize(value,MinValue,MaxValue):\n",
    "    '''DeNormalize the input value between specific range\n",
    " \n",
    "    Args:\n",
    "     value = pixel value\n",
    "     MinValue = Old Min value\n",
    "     MaxValue = Old Max value\n",
    " \n",
    "   Return:\n",
    "    Normalized Value\n",
    "    ''' \n",
    "    MinNormalize_val = -128\n",
    "    MaxNormalize_val = 127\n",
    "    value = MinNormalize_val + (((MaxNormalize_val - MinNormalize_val) * (value - MinValue)) / (MaxValue - MinValue))\n",
    "    return value\n",
    "\n",
    "def Frobenius_Norm(M):\n",
    "    '''Calculate Frobenius Normalization using formula Sqrt( sum(each (values^2) in input) )\n",
    " \n",
    "    Args:\n",
    "     M: Input Tensor     \n",
    "    '''\n",
    "    return tf.reduce_sum(M ** 2) ** 0.5\n",
    "\n",
    "def TriainModel(Input,H,W):\n",
    "    global Batch_size\n",
    " \n",
    "    #region low level Net\n",
    "    print(\"Intialize Low level Net\")\n",
    " \n",
    " \n",
    "    lowLev_layer1 = tf.nn.relu(Conv2d(Input, Low_weights['W_conv1'],2) + Low_biases['b_conv1']) \n",
    "    lowLev_layer2 = tf.nn.relu(Conv2d(lowLev_layer1, Low_weights['W_conv2'], 1) + Low_biases['b_conv2']) \n",
    "    lowLev_layer3 = tf.nn.relu(Conv2d(lowLev_layer2, Low_weights['W_conv3'], 2) + Low_biases['b_conv3']) \n",
    "    lowLev_layer4 = tf.nn.relu(Conv2d(lowLev_layer3, Low_weights['W_conv4'], 1) + Low_biases['b_conv4']) \n",
    "    lowLev_layer5 = tf.nn.relu(Conv2d(lowLev_layer4, Low_weights['W_conv5'], 2) + Low_biases['b_conv5']) \n",
    "    lowLev_layer6 = tf.nn.relu(Conv2d(lowLev_layer5, Low_weights['W_conv6'], 1) + Low_biases['b_conv6']) \n",
    " \n",
    "    #endregion\n",
    " \n",
    "    #region Mid level Net\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Intialize Mid level Net\")\n",
    " \n",
    " \n",
    "    MidLev_layer1 = tf.nn.relu(Conv2d(lowLev_layer6, Mid_weights['W_conv1'], 1) + Mid_biases['b_conv1']) \n",
    "    MidLev_layer2 = tf.nn.relu(Conv2d(MidLev_layer1, Mid_weights['W_conv2'], 1) + Mid_biases['b_conv2']) \n",
    " \n",
    "    #endregion\n",
    " \n",
    "    #region Global level Net\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Intialize Global Level Net\")\n",
    " \n",
    "    GlobalLev_layer1 = tf.nn.relu(Conv2d(lowLev_layer6, Global_weights['W_conv1'], 2) + Global_biases['b_conv1']) \n",
    "    GlobalLev_layer2 = tf.nn.relu(Conv2d(GlobalLev_layer1, Global_weights['W_conv2'], 1) + Global_biases['b_conv2']) \n",
    "    GlobalLev_layer3 = tf.nn.relu(Conv2d(GlobalLev_layer2, Global_weights['W_conv3'], 2) + Global_biases['b_conv3']) \n",
    "    GlobalLev_layer4 = tf.nn.relu(Conv2d(GlobalLev_layer3, Global_weights['W_conv4'], 1) + Global_biases['b_conv4']) \n",
    " \n",
    "    #endregion\n",
    " \n",
    "    #region ML Net\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Intialize ML Net\")\n",
    " \n",
    "    ML_Net = ConstructML(GlobalLev_layer4,3,[1024,512,256])\n",
    "    #endregion\n",
    " \n",
    "    #region Fusion Layer\n",
    "    print(\"--------------------------\")\n",
    "    print(\"initialize Fusion layer\")   \n",
    "    Fuse = Fusion_layer(MidLev_layer2, ML_OUTPUT,Batch_size,224,224)\n",
    "    #endregion\n",
    " \n",
    "    #region Colorization Net\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Intialize Colorization Net\")\n",
    "    print(\"--------------------------\")\n",
    " \n",
    " \n",
    "    Color_layer1 = tf.nn.relu(Conv2d(Fuse, Color_weights['W_conv1'], 1) + Color_biases['b_conv1'])     \n",
    " \n",
    "    Color_layer2 = tf.nn.relu(Conv2d(Color_layer1, Color_weights['W_conv2'], 1) + Color_biases['b_conv2'])     \n",
    "    Color_layer2_up = tf.image.resize_nearest_neighbor(Color_layer2,[56,56])\n",
    " \n",
    "    Color_layer3 = tf.nn.relu(Conv2d(Color_layer2_up, Color_weights['W_conv3'], 1) + Color_biases['b_conv3']) \n",
    "    Color_layer4 = tf.nn.relu(Conv2d(Color_layer3, Color_weights['W_conv4'], 1) + Color_biases['b_conv4']) \n",
    "    Color_layer4_up = tf.image.resize_nearest_neighbor(Color_layer4,[112,112])\n",
    " \n",
    "    Color_layer5 = tf.nn.relu(Conv2d(Color_layer4_up, Color_weights['W_conv5'], 1) + Color_biases['b_conv5']) \n",
    "    Color_layer6 = tf.nn.sigmoid(Conv2d(Color_layer5, Color_weights['W_conv6'], 1) + Color_biases['b_conv6']) \n",
    " \n",
    "    Output = tf.image.resize_nearest_neighbor(Color_layer6,[224,224])\n",
    " \n",
    "    #endregion\n",
    " \n",
    "    return Output\n",
    "\n",
    "def TestModel(Input1,input2,H,W):\n",
    " \n",
    "    #region low level Net\n",
    " \n",
    "    lowLev_layer1 = tf.nn.relu(Conv2d(input2, Low_weights['W_conv1'],2) + Low_biases['b_conv1']) \n",
    "    lowLev_layer2 = tf.nn.relu(Conv2d(lowLev_layer1, Low_weights['W_conv2'], 1) + Low_biases['b_conv2']) \n",
    "    lowLev_layer3 = tf.nn.relu(Conv2d(lowLev_layer2, Low_weights['W_conv3'], 2) + Low_biases['b_conv3']) \n",
    "    lowLev_layer4 = tf.nn.relu(Conv2d(lowLev_layer3, Low_weights['W_conv4'], 1) + Low_biases['b_conv4']) \n",
    "    lowLev_layer5 = tf.nn.relu(Conv2d(lowLev_layer4, Low_weights['W_conv5'], 2) + Low_biases['b_conv5']) \n",
    "    lowLev_layer6 = tf.nn.relu(Conv2d(lowLev_layer5, Low_weights['W_conv6'], 1) + Low_biases['b_conv6']) \n",
    " \n",
    "    #endregion\n",
    " \n",
    "   #region low level Net\n",
    " \n",
    "    lowLev2_layer1 = tf.nn.relu(Conv2d(Input1, Low_weights['W_conv1'],2) + Low_biases['b_conv1']) \n",
    "    lowLev2_layer2 = tf.nn.relu(Conv2d(lowLev2_layer1, Low_weights['W_conv2'], 1) + Low_biases['b_conv2']) \n",
    "    lowLev2_layer3 = tf.nn.relu(Conv2d(lowLev2_layer2, Low_weights['W_conv3'], 2) + Low_biases['b_conv3']) \n",
    "    lowLev2_layer4 = tf.nn.relu(Conv2d(lowLev2_layer3, Low_weights['W_conv4'], 1) + Low_biases['b_conv4']) \n",
    "    lowLev2_layer5 = tf.nn.relu(Conv2d(lowLev2_layer4, Low_weights['W_conv5'], 2) + Low_biases['b_conv5']) \n",
    "    lowLev2_layer6 = tf.nn.relu(Conv2d(lowLev2_layer5, Low_weights['W_conv6'], 1) + Low_biases['b_conv6']) \n",
    " \n",
    "    #endregion\n",
    " \n",
    "    #region Mid level Net\n",
    " \n",
    "    MidLev_layer1 = tf.nn.relu(Conv2d(lowLev2_layer6, Mid_weights['W_conv1'], 1) + Mid_biases['b_conv1']) \n",
    "    MidLev_layer2 = tf.nn.relu(Conv2d(MidLev_layer1, Mid_weights['W_conv2'], 1) + Mid_biases['b_conv2']) \n",
    " \n",
    "    #endregion\n",
    " \n",
    "    #region Global level Net\n",
    "    \n",
    "    GlobalLev_layer1 = tf.nn.relu(Conv2d(lowLev_layer6, Global_weights['W_conv1'], 2) + Global_biases['b_conv1']) \n",
    "    GlobalLev_layer2 = tf.nn.relu(Conv2d(GlobalLev_layer1, Global_weights['W_conv2'], 1) + Global_biases['b_conv2']) \n",
    "    GlobalLev_layer3 = tf.nn.relu(Conv2d(GlobalLev_layer2, Global_weights['W_conv3'], 2) + Global_biases['b_conv3']) \n",
    "    GlobalLev_layer4 = tf.nn.relu(Conv2d(GlobalLev_layer3, Global_weights['W_conv4'], 1) + Global_biases['b_conv4']) \n",
    " \n",
    "    #endregion\n",
    " \n",
    "    #region ML Net\n",
    "\n",
    "    ML_Net = ConstructML(GlobalLev_layer4,3,[1024,512,256])\n",
    "    #endregion\n",
    " \n",
    "    #region Fusion Layer\n",
    "    Fuse = Fusion_layer(MidLev_layer2, ML_OUTPUT,1,H,W)\n",
    "    #endregion\n",
    " \n",
    "    #region Colorization Net\n",
    "    H= tf.cast((H/8), tf.int32) \n",
    "    W= tf.cast((W/8), tf.int32) \n",
    "    Color_layer1 = tf.nn.relu(Conv2d(Fuse, Color_weights['W_conv1'], 1) + Color_biases['b_conv1'])     \n",
    " \n",
    "    Color_layer2 = tf.nn.relu(Conv2d(Color_layer1, Color_weights['W_conv2'], 1) + Color_biases['b_conv2'])     \n",
    "    Color_layer2_up = tf.image.resize_nearest_neighbor(Color_layer2,[H*2,W*2])\n",
    " \n",
    "    Color_layer3 = tf.nn.relu(Conv2d(Color_layer2_up, Color_weights['W_conv3'], 1) + Color_biases['b_conv3']) \n",
    "    Color_layer4 = tf.nn.relu(Conv2d(Color_layer3, Color_weights['W_conv4'], 1) + Color_biases['b_conv4']) \n",
    "    Color_layer4_up = tf.image.resize_nearest_neighbor(Color_layer4,[H*4,W*4])\n",
    " \n",
    "    Color_layer5 = tf.nn.relu(Conv2d(Color_layer4_up, Color_weights['W_conv5'], 1) + Color_biases['b_conv5']) \n",
    "    Color_layer6 = tf.nn.sigmoid(Conv2d(Color_layer5, Color_weights['W_conv6'], 1) + Color_biases['b_conv6']) \n",
    " \n",
    "    Output = tf.image.resize_nearest_neighbor(Color_layer6,[H*8,W*8])\n",
    " \n",
    " \n",
    "    #endregion\n",
    "    return Output\n",
    "\n",
    "def Train():\n",
    "    global AbColores_values\n",
    "    global CurrentBatch_indx\n",
    "    global GreyImages_Batch\n",
    "    global EpochsNum\n",
    "    global ExamplesNum\n",
    "    global Batch_size\n",
    "    Input_images = tf.placeholder(dtype=tf.float32,shape=[None,224,224,1],name=\"X_inputs\")\n",
    "    Ab_Labels_tensor = tf.placeholder(dtype=tf.float32,shape=[None,224,224,2],name=\"Labels_inputs\")\n",
    "    Prediction = TriainModel(Input_images) \n",
    "    Colorization_MSE = tf.reduce_mean((Frobenius_Norm(tf.sub(Prediction,Ab_Labels_tensor))))\n",
    "    Optmizer = tf.train.AdamOptimizer().minimize(Colorization_MSE)\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver = tf.train.import_meta_graph('Model Directory/our_model.meta')\n",
    "    saver.restore(sess, 'Model Directory/our_model')\n",
    "    PrevLoss = 0\n",
    "    for epoch in range(EpochsNum):\n",
    "        epoch_loss = 0\n",
    "        CurrentBatch_indx = 1\n",
    "        for i in range(int(ExamplesNum / Batch_size)):#Over batches\n",
    "           print(\"Batch Num \",i + 1)\n",
    "           ReadNextBatch()\n",
    "           a, c = sess.run([Optmizer,Colorization_MSE],feed_dict={Input_images:GreyImages_Batch,Ab_Labels_tensor:AbColores_values})\n",
    "           epoch_loss += c\n",
    "        print(\"epoch: \",epoch + 1, \",Loss: \",epoch_loss,\", Diff:\",PrevLoss - epoch_loss)\n",
    "        PrevLoss = epoch_loss\n",
    "\n",
    "    saver.save(sess, 'Model Directory/our_model',write_meta_graph=False)\n",
    "\n",
    "def Test(image_Name,flag):\n",
    "    if(flag==False):\n",
    "        saver = tf.train.Saver()\n",
    "        saver = tf.train.import_meta_graph('Model Directory/our_model.meta')\n",
    "        saver.restore(sess, 'Model Directory/our_model')\n",
    "    GreyImagesRezied_Batch = []\n",
    "    OriginalImage_Batch=[]\n",
    "    Original_Img = Image.open(TestingImgPath+image_Name).convert('RGB').convert('L')  \n",
    "    width,height=Original_Img.size\n",
    "    Original_Img = Original_Img.resize((int(width/8) * 8,int(height/8) * 8),Image.ANTIALIAS)      \n",
    "   \n",
    "    Grey_img = Original_Img.resize((224,224),Image.ANTIALIAS)      \n",
    "    Original_Img = np.asanyarray(Original_Img) \n",
    "    Grey_img = np.asanyarray(Grey_img) \n",
    "\n",
    "    img_shape = Original_Img.shape\n",
    "    Original_reshaped = Original_Img.reshape(img_shape[0],img_shape[1], GreyChannels)#[H,W,1]\n",
    "    OriginalImage_Batch.append(Original_reshaped)#[#imgs,224,224,1]\n",
    "    img_reshaped = Grey_img.reshape(224, 224, GreyChannels)#[224,224,1]\n",
    "    GreyImagesRezied_Batch.append(img_reshaped)#[#imgs,224,224,1]\n",
    "\n",
    "    TestImage = tf.placeholder(dtype=tf.float32,shape=[1,224,224,1])\n",
    "    original = tf.placeholder(dtype=tf.float32,shape=[1,None,None,1])\n",
    "    Prediction = TestModel(original,TestImage,Original_Img.shape[0],Original_Img.shape[1]) \n",
    "    Chrominance = sess.run(Prediction,feed_dict={TestImage:GreyImagesRezied_Batch,original:OriginalImage_Batch})\n",
    "\n",
    "    NewImg = np.empty((Original_Img.shape[0],Original_Img.shape[1],3))\n",
    "    for i in range(len(Original_reshaped[:,1,0])):\n",
    "      for j in range(len(Original_reshaped[1,:,0])):\n",
    "         NewImg[i,j,0]= 0 + ( (Original_reshaped[i,j,0] - 0) * (100 - 0) / (255 - 0) )  \n",
    "    NewImg[:,:,1] = DeNormalize(Chrominance[0,:,:,0],0,1)\n",
    "    NewImg[:,:,2] = DeNormalize(Chrominance[0,:,:,1],0,1)\n",
    "    NewImg = color.lab2rgb(NewImg)\n",
    "    plt.imsave(ResultImagePath+image_Name[0:-4]+\"_Colored\"+image_Name[len(image_Name)-4:],NewImg)\n",
    "#------------------------------------------------\n",
    "def call(flag):\n",
    "  \n",
    "    image_Name = input(\" Enter the image name : \")\n",
    "    print(\"\")\n",
    "    print(\" loading ...\")\n",
    "    print(\"\")\n",
    "    Test(image_Name,flag)\n",
    "    print(\" Colored Image is saved in the same DIR.\")\n",
    "    print(\"\")\n",
    "    Desire = input(\" Try Again ? Y/N ? \")\n",
    "    print(\"\")\n",
    "    if (Desire == 'Y' or Desire == 'y'):\n",
    "        print(\"\")\n",
    "        call(True)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"           ---- DEEP LEARNING COLORIZATION FOR VISUAL MEDIA ----           \")\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "call(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
